import asyncio
import copy
import json
import requests
import traceback
import re
import random
from os.path import join, exists, isfile
from os import system, listdir
import os, time
from datetime import datetime, timezone
import jieba
import numpy as np
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
from PIL import Image
from botoy import mark_recv, ctx, action, file_to_base64, jconfig, async_run, to_async
import logging
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

logger = logging.getLogger(__name__)

resource_path = 'resources/wordcloud'
from utils.tz import beijingnow
from utils import fileio

system(f"mkdir -p {join(resource_path, 'chat_history')}")
system(f"mkdir -p {join(resource_path, 'group_wordcloud')}")

# ä½¿ç”¨ APScheduler è¿›è¡Œå®šæ—¶ä»»åŠ¡è°ƒåº¦
scheduler = AsyncIOScheduler()

with open(join(resource_path, 'group_enable.json'), 'r') as f:
    group_enable = json.load(f)

# å®šä¹‰å¤šç§ç°ä»£åŒ–çš„æ¸å˜è‰²å½©æ–¹æ¡ˆ
def get_gradient_color_func(color_scheme='default'):
    """
    è¿”å›ä¸€ä¸ªé¢œè‰²å‡½æ•°ï¼Œç”¨äºè¯äº‘çš„æ¸å˜é…è‰²
    æ”¯æŒå¤šç§æµè¡Œçš„é…è‰²æ–¹æ¡ˆ
    """
    color_schemes = {
        'sunset': [  # æ—¥è½éœå…‰
            '#FF6B6B', '#FFE66D', '#FF8E53', '#FE4A49', '#F9844A'
        ],
        'ocean': [  # æµ·æ´‹æ¸å˜
            '#00D4FF', '#0099CC', '#0066CC', '#003D99', '#5DADE2'
        ],
        'forest': [  # æ£®æ—ç»¿æ„
            '#2ECC71', '#27AE60', '#1ABC9C', '#16A085', '#52BE80'
        ],
        'purple_dream': [  # ç´«è‰²æ¢¦å¹»
            '#9B59B6', '#8E44AD', '#AF7AC5', '#D2B4DE', '#BB8FCE'
        ],
        'warm': [  # æ¸©æš–æ©™çº¢
            '#E74C3C', '#EC7063', '#F39C12', '#F8B739', '#E67E22'
        ],
        'cool': [  # å†·è‰²è°ƒ
            '#3498DB', '#5DADE2', '#85C1E9', '#AED6F1', '#2980B9'
        ],
        'aurora': [  # æå…‰è‰²
            '#A29BFE', '#6C5CE7', '#FD79A8', '#FDCB6E', '#00B894'
        ],
        'candy': [  # ç³–æœè‰²
            '#FF6B9D', '#FFC93C', '#C3BEF7', '#A1EAFB', '#FFB6B9'
        ]
    }
    
    colors = color_schemes.get(color_scheme, color_schemes['sunset'])
    
    def color_func(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None):
        # æ ¹æ®å­—ä½“å¤§å°é€‰æ‹©é¢œè‰²ï¼Œå¤§çš„è¯ç”¨æ›´é²œè‰³çš„é¢œè‰²
        if font_size:
            # å½’ä¸€åŒ–å­—ä½“å¤§å°
            idx = min(int((font_size / 100) * len(colors)), len(colors) - 1)
        else:
            idx = random.randint(0, len(colors) - 1)
        return colors[idx]
    
    return color_func

@to_async
def gen_wordcloud(word_list_str: str, wordcloud_data: dict, img_path: str):
    wordcloud = WordCloud(**wordcloud_data).generate(word_list_str)
    wordcloud.to_file(img_path)

# ä¸ä½¿ç”¨å¼‚æ­¥
def gen_wordcloud_sync(word_list_str: str, wordcloud_data: dict, img_path: str):
    wordcloud = WordCloud(**wordcloud_data).generate(word_list_str)
    wordcloud.to_file(img_path)
    
async def gen_wordcloud_task():
    """å®šæ—¶ç”Ÿæˆè¯äº‘ä»»åŠ¡ - ç”± APScheduler è°ƒåº¦"""
    global group_enable
    # åœç”¨è¯
    stopwords = set()
    t = requests.get('https://raw.githubusercontent.com/hoochanlon/cn_stopwords/main/baidu_stopwords.txt').text.split()
    content = [line.strip() for line in t]
    stopwords.update(content)
    
    # ä½¿ç”¨å›ºå®šçš„ litchi_newyear mask
    mask = None
    colors = None
    mask_path = join(resource_path, 'masks/litchi_newyear.png')
    if exists(mask_path):
        mask_image = Image.open(mask_path)
        mask = np.array(mask_image)
        colors = ImageColorGenerator(mask)
    
    # jieba.enable_paddle()
    for group_id in group_enable:
        # if group_id != 723979982:
        #     continue
        try:
            file_path = join(resource_path, f'chat_history/{group_id}.txt')
            lock_path = join(resource_path, f'chat_history/{group_id}.lock')
            STALE_SECONDS = 60 * 60 * 2  # 2 hours

            # å°è¯•åˆ›å»ºåŸå­ lock æ–‡ä»¶ï¼Œè‹¥å·²å­˜åœ¨åˆ™è·³è¿‡ï¼›è‹¥ lock è¿‡æ—§åˆ™æ¸…ç†åé‡è¯•
            lock_created = False
            try:
                fd = os.open(lock_path, os.O_CREAT | os.O_EXCL | os.O_WRONLY)
                os.close(fd)
                lock_created = True
            except FileExistsError:
                try:
                    if time.time() - os.path.getmtime(lock_path) > STALE_SECONDS:
                        os.remove(lock_path)
                        fd = os.open(lock_path, os.O_CREAT | os.O_EXCL | os.O_WRONLY)
                        os.close(fd)
                        lock_created = True
                except Exception:
                    lock_created = False

            if not lock_created:
                # å…¶ä»–è¿›ç¨‹/åç¨‹æ­£åœ¨å¤„ç†ï¼›è·³è¿‡ä»¥é¿å…é‡å¤ç”Ÿæˆ
                continue

            try:
                text_list = []
                if exists(file_path):
                    text_list = await fileio.read_lines(file_path)
                
                word_list = []
                for text in text_list:
                    text = text.strip()
                    if text:
                        # åˆ†è¯
                        # jieba.enable_paddle():
                        # jbc = list(jieba.cut(text, use_paddle=True))
                        # words = [word for word in jbc if word not in stopwords]
                        # word_list.extend(words)
                        # ä¸åˆ†è¯
                        word_list.append(text)
                
                if not word_list:
                    t = 'æœ¬æ—¥ä½ ç¾¤ä¸€å¥æ­£ç»è¯æ²¡æœ‰ï¼Œæœäº†'
                    await action.sendGroupText(group=group_id, text=t)
                else:
                    word_list_str = " ".join(word_list)
                    
                    # ä½¿ç”¨maskæ—¶çš„ä¼˜åŒ–é…ç½®
                    if mask is not None:
                        # ä½¿ç”¨ mask æ—¶çš„å‚æ•°é…ç½®
                        wordcloud_data = dict(
                            background_color="white",  # ç™½è‰²èƒŒæ™¯æ›´é€‚åˆå±•ç¤ºmaskå½¢çŠ¶
                            max_words=5000,  # ä½¿ç”¨maskæ—¶å¯ä»¥æ”¾æ›´å¤šè¯
                            width=2000,  # æ ¹æ®maskè°ƒæ•´å°ºå¯¸
                            height=2000,
                            min_font_size=15,  # ç¨å¤§çš„æœ€å°å­—ä½“ï¼Œç¡®ä¿æ¸…æ™°
                            max_font_size=200,  # æ›´å¤§çš„å­—ä½“ä»¥å¡«å……maskå½¢çŠ¶
                            stopwords=stopwords,
                            mask=mask,  # ä½¿ç”¨mask
                            color_func=colors,  # ä»maskå›¾ç‰‡æå–é¢œè‰²
                            collocations=False,
                            font_path=join(resource_path, 'HarmonyOS.ttf'),
                            relative_scaling=0.4,  # é™ä½ç›¸å¯¹ç¼©æ”¾ï¼Œè®©è¯è¯­å¤§å°åˆ†å¸ƒæ›´å‡åŒ€
                            prefer_horizontal=0.75,  # æ›´å¤šæ°´å¹³è¯è¯­ï¼Œæ›´æ˜“è¯»
                            margin=1,  # æ›´ç´§å¯†çš„é—´è·ä»¥å¡«å……mask
                            contour_width=2,  # æ·»åŠ è½®å»“çº¿å®½åº¦
                            contour_color='#FF6B6B',  # è½®å»“é¢œè‰²ï¼ˆå¯é€‰ï¼Œå¯ä»¥æ³¨é‡Šæ‰ï¼‰
                            random_state=None,
                        )
                        scheme_info = "è”ææ–°å¹´ä¸»é¢˜ (Litchi New Year)"
                    else:
                        # æ²¡æœ‰maskæ—¶ä½¿ç”¨æ¸å˜è‰²æ–¹æ¡ˆ
                        color_schemes_list = ['sunset', 'ocean', 'forest', 'purple_dream', 
                                             'warm', 'cool', 'aurora', 'candy']
                        chosen_scheme = random.choice(color_schemes_list)
                        color_func = get_gradient_color_func(chosen_scheme)
                        
                        wordcloud_data = dict(
                            background_color="white",
                            max_words=3000,
                            height=1080,
                            width=1920,
                            min_font_size=10,
                            max_font_size=150,
                            stopwords=stopwords,
                            color_func=color_func,
                            collocations=False,
                            font_path=join(resource_path, 'HarmonyOS.ttf'),
                            relative_scaling=0.5,
                            prefer_horizontal=0.7,
                            margin=2,
                            random_state=None,
                        )
                        scheme_info = chosen_scheme
                    
                    img_path = join(resource_path, f'group_wordcloud/{group_id}.png')
                    
                    gen_wordcloud_sync(word_list_str, wordcloud_data, img_path)
                    # await gen_wordcloud(word_list_str, wordcloud_data, img_path)
                    # await async_run(gen_wordcloud_sync, word_list_str, wordcloud_data, img_path)
                    
                    t = f"ğŸ“Š ä»Šæ—¥è¯äº‘å·²é€è¾¾\nä»Šæ—¥ä½ ç¾¤å…±èŠäº†{len(text_list)}å¥è¯"
                    await action.sendGroupPic(group=group_id, text=t, base64=file_to_base64(img_path))
                
                # æ¸…ç©ºæ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if exists(file_path):
                    await fileio.clear_file(file_path)
                
                await asyncio.sleep(10)
            finally:
                try:
                    if os.path.exists(lock_path):
                        os.remove(lock_path)
                except Exception:
                    pass
        except Exception as e:
            logger.exception(f'wordcloud scheduler error group_id: {group_id}')
            t = f'wordcloud scheduler error\ngroup_id: {group_id}\ntraceback: {traceback.format_exc()}'
            await action.sendGroupText(group=1014696092, text=t)


def remove_abstract_content(text:str):
    if text.startswith('{') and text.endswith('}'):
        return ''
    if text.startswith('<') and text.endswith('>'):
        return ''
    # æ’é™¤é“¾æ¥
    link_pattern = re.compile(r'https?://\S+|www\.\S+')
    text = link_pattern.sub('', text)
    # æ’é™¤@ 
    # NOTE: ç”±äº@çš„åå­—ä¸­è‹¥å‡ºç°ç©ºæ ¼å°†æ— æ³•å®Œæ•´å‰”é™¤ï¼Œ
    #       äºæ˜¯å°†åŒ…å«@çš„æ•´å¥è¯ç›´æ¥æ’é™¤æ‰
    # mention_pattern = re.compile(r'@\S+\s?')
    # text = mention_pattern.sub('', text)
    if '@' in text:
        return ''
    return text
async def log_chat():
    global group_enable
    if msg := ctx.g:
        if msg.from_user != jconfig.qq and msg.from_group in group_enable:
            msg_text = remove_abstract_content(msg.text)
            if msg_text:
                msg_text = msg_text + '\n'
                await fileio.addline(join(resource_path, f'chat_history/{msg.from_group}.txt'), msg_text)
mark_recv(log_chat)


# é…ç½® APScheduler å®šæ—¶ä»»åŠ¡

# ========== æµ‹è¯•ä»»åŠ¡ï¼šæ¯åˆ†é’Ÿæ‰§è¡Œ ==========
# scheduler.add_job(
#     gen_wordcloud_task,
#     CronTrigger(minute='*'),  # æ¯åˆ†é’Ÿæ‰§è¡Œ
#     id='wordcloud_test',
#     name='è¯äº‘æµ‹è¯•(æ¯åˆ†é’Ÿ)',
#     replace_existing=True
# )

# ========== ç”Ÿäº§ä»»åŠ¡ï¼šæ¯å¤© 00:15 æ‰§è¡Œ ==========
scheduler.add_job(
    gen_wordcloud_task,
    CronTrigger(hour=0, minute=15),  # æ¯å¤© 00:15
    id='wordcloud_daily',
    name='æ¯æ—¥è¯äº‘ç”Ÿæˆ',
    replace_existing=True
)

# å»¶è¿Ÿå¯åŠ¨ schedulerï¼Œç›´åˆ°äº‹ä»¶å¾ªç¯è¿è¡Œ
_scheduler_started = False

async def start_scheduler():
    """åœ¨äº‹ä»¶å¾ªç¯è¿è¡Œåå¯åŠ¨ scheduler"""
    global _scheduler_started
    if not _scheduler_started:
        scheduler.start()
        _scheduler_started = True
        logger.info("è¯äº‘å®šæ—¶ä»»åŠ¡å·²é…ç½®")

mark_recv(start_scheduler)
